# Copyright (c) 2025 Harrold Holdings GmbH
# Licensed under the Apache License, Version 2.0
# See LICENSE file in the project root for full license information.

# Media Intelligence Pipeline - Compose Configuration
# Compatible with Podman Compose and Docker Compose

version: '3.8'

services:
  media-intelligence:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: media-intelligence
    image: media-intelligence:latest

    # Volume mounts
    volumes:
      # Input audio files (read-only for security)
      - ./data/input:/data/input:ro
      # Output results (read-write)
      - ./data/output:/data/output:rw
      # Model cache (persistent across runs)
      - ./cache:/root/.cache:rw

    # Environment variables
    environment:
      # HuggingFace token for pyannote diarization
      - HUGGINGFACE_TOKEN=${HUGGINGFACE_TOKEN}
      # Thread limits for CPU processing
      - OMP_NUM_THREADS=4
      - MKL_NUM_THREADS=4
      # Model cache location
      - TRANSFORMERS_CACHE=/root/.cache/huggingface
      - HF_HOME=/root/.cache/huggingface

    # Resource limits
    deploy:
      resources:
        limits:
          cpus: '4.0'
          memory: 8G
        reservations:
          cpus: '2.0'
          memory: 4G

    # Security options
    security_opt:
      - no-new-privileges:true

    # Read-only root filesystem (with exceptions for cache/output)
    read_only: true
    tmpfs:
      - /tmp:size=1G

    # Network isolation (no external network needed for processing)
    network_mode: none

    # Restart policy
    restart: "no"

# Named volumes (optional - use for persistent storage)
# volumes:
#   model-cache:
#     driver: local
